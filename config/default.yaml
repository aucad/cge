# *******************************************
# Each experiment must define the following:
name: # dataset display name
dataset: # path to data set file (CSV)
constraints: # dictionary
# *******************************************

cls: xgb # target classifier
attack: zoo # choice attack
validate: false # enforce constrains during attack
out: result # output directory
folds: 5 # K-folds (min: 2)
desc: # optional details or experiment notes


# *******************************************
# CLASSIFIER CONFIGURATIONS

# XGBoost Classifier
# https://tinyurl.com/4xdnf9vs
xgb:
  num_boost_round: 20
  params:
    eta: 0.3
    gamma: 0
    max_depth: 6
    min_child_weight: 1
    tree_method: exact
    objective: multi:softprob

# Keras Deep Neural Network
dnn:
  layers: [ 60 ]
  model_fit:
    epochs: 80
    batch_size: 50
    shuffle: True
    verbose: False

# *******************************************
# ATTACK CONFIGURATIONS

# Zeroth-Order Optimization (ZOO)
# https://tinyurl.com/mad2v59a
zoo:
  confidence: 0.25
  learning_rate: 0.1
  binary_search_steps: 10
  initial_const: 0.001
  abort_early: True
  use_resize: False
  use_importance: False
  variable_h: 0.3
  targeted: False
  nb_parallel: 5
  batch_size: 1
  verbose: True
  max_iter: 5

# Projected Gradient Descent (PGD)
# https://tinyurl.com/b88f6djr
pgd:
  norm: none
  eps: 0.3
  eps_step: 0.1
  random_eps: False
  max_iter: 20
  targeted: False
  num_random_init: 0
  batch_size: 1
  verbose: True

# HopSkipJump
# https://tinyurl.com/bddm9byb
hsj:
  max_iter: 10 # Maximum number of iterations.
  verbose: True # Show progress bars.
  batch_size: 64 # size of the batch used by the estimator during inference.
  targeted: False # should the attack target one specific class.
  max_eval: 1000 # Max evaluations for estimating gradient.
  init_eval: 100 # Initial number of evaluations for estimating gradient.
  init_size: 100 # Max trials for initial generation of adversarial examples.
  norm: 2 # Order of the norm. Possible values: "inf" or 2.

