# *******************************************
# Each experiment must define the following:
name: # dataset display name
dataset: # path to data set file (CSV)
constraints: # dictionary
# *******************************************

cls: xgb # target classifier
attack: zoo # choice attack
validate: false # enforce constrains during attack
out: result # output directory
folds: 5 # K-folds (min: 2)
desc: # optional details or experiment notes


# *******************************************
# CLASSIFIER CONFIGURATIONS

# XGBoost Classifier
# https://tinyurl.com/4xdnf9vs
xgb:
  num_boost_round: 20
  params:
    eta: 0.3
    gamma: 0
    max_depth: 6
    min_child_weight: 1
    tree_method: exact
    objective: multi:softprob

# Keras Deep Neural Network
# https://tinyurl.com/5bffyuev
dnn:
  layers: [ 60 ]
  params:
    use_logits: True
  model_fit:
    epochs: 80
    batch_size: 64
    shuffle: True
    verbose: False

# *******************************************
# ATTACK CONFIGURATIONS

# Zeroth-Order Optimization (ZOO)
# https://tinyurl.com/mad2v59a
zoo:
  confidence: 0.25 # Confidence of adversarial examples
  learning_rate: 0.1 # Smaller values produce better results, but are slower to converge.
  max_iter: 5 # maximum number of iterations.
  binary_search_steps: 10 # Number of times to adjust constant with binary search
  initial_const: 0.001 # use to tune the relative importance of distance and confidence
  abort_early: True # abandoned gradient descent when it gets stuck.
  use_resize: False # use the resizing strategy from the paper
  use_importance: False # use importance sampling when choosing coordinates to update.
  nb_parallel: 5 # Number of coordinate updates to run in parallel.
  variable_h: 0.3 #  Step size for numerical estimation of derivatives.
  targeted: False # Should the attack target one specific class.
  batch_size: 1 # size of batches on which adversarial samples are generated.
  verbose: True # show progress bars.

# Projected Gradient Descent (PGD)
# https://tinyurl.com/b88f6djr
pgd:
  norm: "inf"  # of the adversarial perturbation “inf”, 1 or 2.
  eps: 0.3 # Maximum perturbation that the attacker can introduce.
  eps_step: 0.1 # Attack step size (input variation) at each iteration.
  random_eps: False # epsilon is drawn randomly from truncated normal distribution.
  decay: # Decay factor for accumulating the velocity vector when using momentum.
  max_iter: 20 # The maximum number of iterations.
  targeted: False # attack is targeted (True) or untargeted (False).
  num_random_init: 10 # Number of random initialisations within the epsilon ball.
  batch_size: 64 # Size of the batch on which adversarial samples are generated.
  verbose: True # Show progress bars.

# HopSkipJump
# https://tinyurl.com/bddm9byb
hsj:
  max_iter: 10 # Maximum number of iterations.
  verbose: True # Show progress bars.
  batch_size: 64 # size of the batch used by the estimator during inference.
  targeted: False # should the attack target one specific class.
  max_eval: 1000 # Max evaluations for estimating gradient.
  init_eval: 100 # Initial number of evaluations for estimating gradient.
  init_size: 100 # Max trials for initial generation of adversarial examples.
  norm: 2 # Order of the norm. Possible values: "inf" or 2.

